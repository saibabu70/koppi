noise_list=["is","a","this","...."]
def _remove_noise(input_text):
  words=input_text.split()
  noise_free_words=[word for word in words if word not in noise_list]
  noise_free_text=" ".join(noise_free_words)
  return noise_free_text
print(_remove_noise("this is a sample text"))

游똂游똂游똂
import re

def _remove_regex(input_text, regex_pattern):
    urls = re.finditer(regex_pattern, input_text)
    for i in urls:
        input_text = re.sub(i.group().strip(), ' ', input_text)
    return input_text

regex_pattern = "#[1w]*"
text = "remove this #hashtag from BVC"
cleaned_text = _remove_regex(text, regex_pattern)
print(cleaned_text)

游냦游냦游냦游냦 (NLP 1st experiment)

from nltk import word_tokenize, pos_tag
text =" I am learning Natural Language processing In Aiml"
pos_tag(word_tokenize(text))

游냥游냥游냥(NLP 4th exp)

doc1="Sugar is bad to consume.My sister likes to have suger,but not my father,"
doc2="My father spends a lot of time drivinf my sister around to dance practice,"
doc3="Doctor suggest that drivinf may cause incresed stress and bold pressure,"
doc_complete=[doc1,doc2,doc3]
doc_clean=[doc.split()for doc in doc_complete]
#import gensim from gensim
#import corpora
import gensim
import os
from gensim import corpora
dictionary=corpora.Dictionary(doc_clean)
doc_term_matrix=[dictionary.doc2bow(doc)for doc in doc_clean]
Lda=gensim.models.ldamodel.LdaModel
Ldamodel=Lda(doc_term_matrix,num_topics=3,id2word=dictionary,passes=50)
print(Ldamodel.print_topics())

游뉧릟뉧릟(NLP 5th)


from sklearn.feature_extraction.text import TfidfVectorizer
obj =TfidfVectorizer ()
corpus=("This is sample document",'another random document' ,'third sample document text')
x=obj.fit_transform (corpus)
print(x)

游내游내游내(6th exp)
